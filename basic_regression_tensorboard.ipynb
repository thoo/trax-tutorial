{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:06.758715Z",
     "iopub.status.busy": "2020-12-04T15:35:06.758464Z",
     "iopub.status.idle": "2020-12-04T15:35:37.278247Z",
     "shell.execute_reply": "2020-12-04T15:35:37.277568Z",
     "shell.execute_reply.started": "2020-12-04T15:35:06.758651Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.supervised import lr_schedules, training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "## Generate data for linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.279761Z",
     "iopub.status.busy": "2020-12-04T15:35:37.279529Z",
     "iopub.status.idle": "2020-12-04T15:35:37.283375Z",
     "shell.execute_reply": "2020-12-04T15:35:37.282592Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.279738Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_linear():\n",
    "    while True:\n",
    "        x = np.random.randint(low=1, high=10) * 1.0\n",
    "        y = x * 2.0 - 1\n",
    "        yield (np.array([x]), np.array([y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.285504Z",
     "iopub.status.busy": "2020-12-04T15:35:37.285250Z",
     "iopub.status.idle": "2020-12-04T15:35:37.290055Z",
     "shell.execute_reply": "2020-12-04T15:35:37.289185Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.285463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2.]), array([3.]))\n"
     ]
    }
   ],
   "source": [
    "data_linear = get_data_linear()\n",
    "print(next(data_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.292101Z",
     "iopub.status.busy": "2020-12-04T15:35:37.291815Z",
     "iopub.status.idle": "2020-12-04T15:35:37.296048Z",
     "shell.execute_reply": "2020-12-04T15:35:37.295266Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.292054Z"
    }
   },
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(trax.data.Batch(50), trax.data.AddLossWeights(),)\n",
    "data_stream = data_pipeline(data_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.297440Z",
     "iopub.status.busy": "2020-12-04T15:35:37.297217Z",
     "iopub.status.idle": "2020-12-04T15:35:37.301161Z",
     "shell.execute_reply": "2020-12-04T15:35:37.300445Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.297412Z"
    }
   },
   "outputs": [],
   "source": [
    "model_linear = tl.Serial(tl.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.302605Z",
     "iopub.status.busy": "2020-12-04T15:35:37.302292Z",
     "iopub.status.idle": "2020-12-04T15:35:37.311629Z",
     "shell.execute_reply": "2020-12-04T15:35:37.311016Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.302575Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Use the same data_stream for both training and evaluation\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=data_stream,\n",
    "    loss_layer=tl.L2Loss(),\n",
    "    optimizer=trax.optimizers.SGD(0.01),\n",
    "    n_steps_per_checkpoint=10,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=data_stream, metrics=[tl.L2Loss()], n_eval_batches=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.313247Z",
     "iopub.status.busy": "2020-12-04T15:35:37.313032Z",
     "iopub.status.idle": "2020-12-04T15:35:37.442811Z",
     "shell.execute_reply": "2020-12-04T15:35:37.442187Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.313221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the training folder\n",
    "!rm -r linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:37.444083Z",
     "iopub.status.busy": "2020-12-04T15:35:37.443918Z",
     "iopub.status.idle": "2020-12-04T15:35:39.043136Z",
     "shell.execute_reply": "2020-12-04T15:35:39.042484Z",
     "shell.execute_reply.started": "2020-12-04T15:35:37.444063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 2\n",
      "Step      1: Ran 1 train steps in 0.15 secs\n",
      "Step      1: train L2Loss |  332.65350342\n",
      "Step      1: eval  L2Loss |  66.64659119\n",
      "\n",
      "Step     10: Ran 9 train steps in 0.03 secs\n",
      "Step     10: train L2Loss |  8.88021851\n",
      "Step     10: eval  L2Loss |  0.44479808\n",
      "\n",
      "Step     20: Ran 10 train steps in 0.03 secs\n",
      "Step     20: train L2Loss |  0.47209778\n",
      "Step     20: eval  L2Loss |  0.40909106\n",
      "\n",
      "Step     30: Ran 10 train steps in 0.03 secs\n",
      "Step     30: train L2Loss |  0.42413217\n",
      "Step     30: eval  L2Loss |  0.40334216\n",
      "\n",
      "Step     40: Ran 10 train steps in 0.04 secs\n",
      "Step     40: train L2Loss |  0.35656795\n",
      "Step     40: eval  L2Loss |  0.37079361\n",
      "\n",
      "Step     50: Ran 10 train steps in 0.04 secs\n",
      "Step     50: train L2Loss |  0.35460237\n",
      "Step     50: eval  L2Loss |  0.33738366\n",
      "\n",
      "Step     60: Ran 10 train steps in 0.04 secs\n",
      "Step     60: train L2Loss |  0.30924049\n",
      "Step     60: eval  L2Loss |  0.33994192\n",
      "\n",
      "Step     70: Ran 10 train steps in 0.03 secs\n",
      "Step     70: train L2Loss |  0.27291662\n",
      "Step     70: eval  L2Loss |  0.28140020\n",
      "\n",
      "Step     80: Ran 10 train steps in 0.03 secs\n",
      "Step     80: train L2Loss |  0.26341251\n",
      "Step     80: eval  L2Loss |  0.28122264\n",
      "\n",
      "Step     90: Ran 10 train steps in 0.03 secs\n",
      "Step     90: train L2Loss |  0.26308465\n",
      "Step     90: eval  L2Loss |  0.25654483\n",
      "\n",
      "Step    100: Ran 10 train steps in 0.03 secs\n",
      "Step    100: train L2Loss |  0.23360479\n",
      "Step    100: eval  L2Loss |  0.20598407\n",
      "\n",
      "Step    110: Ran 10 train steps in 0.03 secs\n",
      "Step    110: train L2Loss |  0.22651048\n",
      "Step    110: eval  L2Loss |  0.19938686\n",
      "\n",
      "Step    120: Ran 10 train steps in 0.03 secs\n",
      "Step    120: train L2Loss |  0.20277464\n",
      "Step    120: eval  L2Loss |  0.18761194\n",
      "\n",
      "Step    130: Ran 10 train steps in 0.03 secs\n",
      "Step    130: train L2Loss |  0.18188682\n",
      "Step    130: eval  L2Loss |  0.17189901\n",
      "\n",
      "Step    140: Ran 10 train steps in 0.03 secs\n",
      "Step    140: train L2Loss |  0.15373699\n",
      "Step    140: eval  L2Loss |  0.17248467\n",
      "\n",
      "Step    150: Ran 10 train steps in 0.03 secs\n",
      "Step    150: train L2Loss |  0.16445327\n",
      "Step    150: eval  L2Loss |  0.15087907\n",
      "\n",
      "Step    160: Ran 10 train steps in 0.03 secs\n",
      "Step    160: train L2Loss |  0.14868698\n",
      "Step    160: eval  L2Loss |  0.15174821\n",
      "\n",
      "Step    170: Ran 10 train steps in 0.03 secs\n",
      "Step    170: train L2Loss |  0.13737752\n",
      "Step    170: eval  L2Loss |  0.12655847\n",
      "\n",
      "Step    180: Ran 10 train steps in 0.03 secs\n",
      "Step    180: train L2Loss |  0.13001502\n",
      "Step    180: eval  L2Loss |  0.11345468\n",
      "\n",
      "Step    190: Ran 10 train steps in 0.03 secs\n",
      "Step    190: train L2Loss |  0.10955505\n",
      "Step    190: eval  L2Loss |  0.12208955\n",
      "\n",
      "Step    200: Ran 10 train steps in 0.03 secs\n",
      "Step    200: train L2Loss |  0.10392560\n",
      "Step    200: eval  L2Loss |  0.09783413\n"
     ]
    }
   ],
   "source": [
    "training_loop = training.Loop(\n",
    "    model_linear, train_task, eval_tasks=[eval_task], output_dir=\"./linear_model\"\n",
    ")\n",
    "training_loop.run(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-05T04:36:10.040691Z",
     "iopub.status.busy": "2020-12-05T04:36:10.040407Z",
     "iopub.status.idle": "2020-12-05T04:36:10.114322Z",
     "shell.execute_reply": "2020-12-05T04:36:10.113606Z",
     "shell.execute_reply.started": "2020-12-05T04:36:10.040657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 3.4674654],\n",
       "             [ 5.358649 ],\n",
       "             [18.596935 ],\n",
       "             [82.89718  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=np.array([[2.0],[3.0],[10.0],[44.0]])\n",
    "model_linear(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "## Generate data for logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.046672Z",
     "iopub.status.busy": "2020-12-04T15:35:39.046419Z",
     "iopub.status.idle": "2020-12-04T15:35:39.051015Z",
     "shell.execute_reply": "2020-12-04T15:35:39.050146Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.046641Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_logistic():\n",
    "    while True:\n",
    "        x = np.random.randint(low=-10, high=10) * 1.0\n",
    "\n",
    "        if x < 0:\n",
    "            y = 0\n",
    "        else:\n",
    "            y = 1\n",
    "\n",
    "        yield (np.array([x]), np.array([y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.054837Z",
     "iopub.status.busy": "2020-12-04T15:35:39.054589Z",
     "iopub.status.idle": "2020-12-04T15:35:39.062166Z",
     "shell.execute_reply": "2020-12-04T15:35:39.061328Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.054808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.]), array([1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_logistic = get_data_logistic()\n",
    "next(data_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.063690Z",
     "iopub.status.busy": "2020-12-04T15:35:39.063370Z",
     "iopub.status.idle": "2020-12-04T15:35:39.068763Z",
     "shell.execute_reply": "2020-12-04T15:35:39.067367Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.063659Z"
    }
   },
   "outputs": [],
   "source": [
    "data_pipeline = trax.data.Serial(trax.data.Batch(50), trax.data.AddLossWeights(),)\n",
    "data_stream = data_pipeline(data_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.070151Z",
     "iopub.status.busy": "2020-12-04T15:35:39.069801Z",
     "iopub.status.idle": "2020-12-04T15:35:39.074578Z",
     "shell.execute_reply": "2020-12-04T15:35:39.073780Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.070119Z"
    }
   },
   "outputs": [],
   "source": [
    "model_logistic = tl.Serial(tl.Dense(1), tl.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.076410Z",
     "iopub.status.busy": "2020-12-04T15:35:39.076135Z",
     "iopub.status.idle": "2020-12-04T15:35:39.085437Z",
     "shell.execute_reply": "2020-12-04T15:35:39.084751Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.076377Z"
    }
   },
   "outputs": [],
   "source": [
    "train_task = training.TrainTask(\n",
    "    labeled_data=data_stream,\n",
    "    loss_layer=tl.BinaryCrossEntropyLoss(),\n",
    "    optimizer=trax.optimizers.Adam(),\n",
    "    lr_schedule=lr_schedules.warmup_and_rsqrt_decay(5, 0.01),\n",
    "    n_steps_per_checkpoint=10,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=data_stream,\n",
    "    metrics=[tl.BinaryCrossEntropyLoss()],\n",
    "    n_eval_batches=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.087021Z",
     "iopub.status.busy": "2020-12-04T15:35:39.086718Z",
     "iopub.status.idle": "2020-12-04T15:35:39.216913Z",
     "shell.execute_reply": "2020-12-04T15:35:39.215798Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.086993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the training folder\n",
    "!rm -r logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.218653Z",
     "iopub.status.busy": "2020-12-04T15:35:39.218365Z",
     "iopub.status.idle": "2020-12-04T15:35:39.381396Z",
     "shell.execute_reply": "2020-12-04T15:35:39.380616Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.218622Z"
    }
   },
   "outputs": [],
   "source": [
    "training_loop = training.Loop(\n",
    "    model_logistic, train_task, eval_tasks=[eval_task], output_dir=\"./logistic_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:39.382768Z",
     "iopub.status.busy": "2020-12-04T15:35:39.382552Z",
     "iopub.status.idle": "2020-12-04T15:35:40.940264Z",
     "shell.execute_reply": "2020-12-04T15:35:40.939618Z",
     "shell.execute_reply.started": "2020-12-04T15:35:39.382742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 2\n",
      "Step      1: Ran 1 train steps in 0.39 secs\n",
      "Step      1: train BinaryCrossEntropyLoss |  6.38921833\n",
      "Step      1: eval  BinaryCrossEntropyLoss |  5.99964046\n",
      "\n",
      "Step     10: Ran 9 train steps in 0.03 secs\n",
      "Step     10: train BinaryCrossEntropyLoss |  6.16716242\n",
      "Step     10: eval  BinaryCrossEntropyLoss |  5.76738453\n",
      "\n",
      "Step     20: Ran 10 train steps in 0.03 secs\n",
      "Step     20: train BinaryCrossEntropyLoss |  5.61083984\n",
      "Step     20: eval  BinaryCrossEntropyLoss |  5.51198244\n",
      "\n",
      "Step     30: Ran 10 train steps in 0.04 secs\n",
      "Step     30: train BinaryCrossEntropyLoss |  5.33438587\n",
      "Step     30: eval  BinaryCrossEntropyLoss |  5.29338312\n",
      "\n",
      "Step     40: Ran 10 train steps in 0.03 secs\n",
      "Step     40: train BinaryCrossEntropyLoss |  5.15196133\n",
      "Step     40: eval  BinaryCrossEntropyLoss |  5.10557127\n",
      "\n",
      "Step     50: Ran 10 train steps in 0.03 secs\n",
      "Step     50: train BinaryCrossEntropyLoss |  4.78580523\n",
      "Step     50: eval  BinaryCrossEntropyLoss |  4.90630245\n",
      "\n",
      "Step     60: Ran 10 train steps in 0.03 secs\n",
      "Step     60: train BinaryCrossEntropyLoss |  4.90844250\n",
      "Step     60: eval  BinaryCrossEntropyLoss |  4.75707054\n",
      "\n",
      "Step     70: Ran 10 train steps in 0.03 secs\n",
      "Step     70: train BinaryCrossEntropyLoss |  4.65331936\n",
      "Step     70: eval  BinaryCrossEntropyLoss |  4.52736616\n",
      "\n",
      "Step     80: Ran 10 train steps in 0.03 secs\n",
      "Step     80: train BinaryCrossEntropyLoss |  4.47772121\n",
      "Step     80: eval  BinaryCrossEntropyLoss |  4.46976852\n",
      "\n",
      "Step     90: Ran 10 train steps in 0.03 secs\n",
      "Step     90: train BinaryCrossEntropyLoss |  4.39461994\n",
      "Step     90: eval  BinaryCrossEntropyLoss |  4.35261250\n",
      "\n",
      "Step    100: Ran 10 train steps in 0.03 secs\n",
      "Step    100: train BinaryCrossEntropyLoss |  4.19667864\n",
      "Step    100: eval  BinaryCrossEntropyLoss |  4.30456114\n",
      "\n",
      "Step    110: Ran 10 train steps in 0.03 secs\n",
      "Step    110: train BinaryCrossEntropyLoss |  4.12881756\n",
      "Step    110: eval  BinaryCrossEntropyLoss |  3.91377449\n",
      "\n",
      "Step    120: Ran 10 train steps in 0.03 secs\n",
      "Step    120: train BinaryCrossEntropyLoss |  4.16614723\n",
      "Step    120: eval  BinaryCrossEntropyLoss |  3.83857489\n",
      "\n",
      "Step    130: Ran 10 train steps in 0.03 secs\n",
      "Step    130: train BinaryCrossEntropyLoss |  3.92670679\n",
      "Step    130: eval  BinaryCrossEntropyLoss |  3.97590208\n",
      "\n",
      "Step    140: Ran 10 train steps in 0.03 secs\n",
      "Step    140: train BinaryCrossEntropyLoss |  3.82500958\n",
      "Step    140: eval  BinaryCrossEntropyLoss |  3.66418409\n",
      "\n",
      "Step    150: Ran 10 train steps in 0.03 secs\n",
      "Step    150: train BinaryCrossEntropyLoss |  3.74771619\n",
      "Step    150: eval  BinaryCrossEntropyLoss |  3.53282046\n",
      "\n",
      "Step    160: Ran 10 train steps in 0.03 secs\n",
      "Step    160: train BinaryCrossEntropyLoss |  3.61915064\n",
      "Step    160: eval  BinaryCrossEntropyLoss |  3.52386856\n",
      "\n",
      "Step    170: Ran 10 train steps in 0.03 secs\n",
      "Step    170: train BinaryCrossEntropyLoss |  3.51643944\n",
      "Step    170: eval  BinaryCrossEntropyLoss |  3.44627380\n",
      "\n",
      "Step    180: Ran 10 train steps in 0.03 secs\n",
      "Step    180: train BinaryCrossEntropyLoss |  3.42600393\n",
      "Step    180: eval  BinaryCrossEntropyLoss |  3.42530560\n",
      "\n",
      "Step    190: Ran 10 train steps in 0.03 secs\n",
      "Step    190: train BinaryCrossEntropyLoss |  3.29475522\n",
      "Step    190: eval  BinaryCrossEntropyLoss |  3.26094484\n",
      "\n",
      "Step    200: Ran 10 train steps in 0.03 secs\n",
      "Step    200: train BinaryCrossEntropyLoss |  3.30643988\n",
      "Step    200: eval  BinaryCrossEntropyLoss |  3.35068202\n"
     ]
    }
   ],
   "source": [
    "training_loop.run(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display using Tensorboard\n",
    "Tensorboard just needs to point to the training folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:40.941461Z",
     "iopub.status.busy": "2020-12-04T15:35:40.941198Z",
     "iopub.status.idle": "2020-12-04T15:35:40.947318Z",
     "shell.execute_reply": "2020-12-04T15:35:40.946668Z",
     "shell.execute_reply.started": "2020-12-04T15:35:40.941435Z"
    }
   },
   "outputs": [],
   "source": [
    "# First load the extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-04T15:35:40.949022Z",
     "iopub.status.busy": "2020-12-04T15:35:40.948735Z",
     "iopub.status.idle": "2020-12-04T15:35:44.991755Z",
     "shell.execute_reply": "2020-12-04T15:35:44.990913Z",
     "shell.execute_reply.started": "2020-12-04T15:35:40.948982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8e26ed678de34d37\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8e26ed678de34d37\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For a linear model,\n",
    "%tensorboard --logdir linear_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitanaconda3virtualenv8d2cff73d4434f4db794d807b7c026ac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
